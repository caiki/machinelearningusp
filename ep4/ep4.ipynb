{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAC0460/5832 - Lista 4: SVM - MNIST\n",
    "\n",
    "### Data de Entrega: 23h55m do dia XX/07/2017\n",
    "\n",
    "##### Classificação de dígitos\n",
    "Os dataset para esta tarefa é uma adaptação do disponível na competição do kaggle de reconhecimento de dígitos (https://www.kaggle.com/c/digit-recognizer) e está disponível em http://vision.ime.usp.br/~caiomr/mac0460_5832/train_svm.csv.gz. O dataset está sob a licença Creative Commons Attribution-Share Alike 3.0 license (https://creativecommons.org/licenses/by-sa/3.0/). O dataset foi zipado, e apenas os dígitos 5 e 6 foram mantidos. Cada linha (amostra) do arquivo contém 257 colunas: a primeira informa o label da amostra (0 para o dígito 5, 1 para o dígito 6) e as outras 256 são os valores dos pixels da imagem (16 x 16) que representa o dígito.\n",
    "\n",
    "Note que esse dataset difere do usado no EP3: as imagens sofreram pequenas rotações e translações aleatórias, além de terem sido escalonadas para o tamanho 16x16. Veja também que pode ser necessário realizar algum tipo de normalização para realizar um treinamento efetivo com SVM. Para auxiliar na normalização dos dados, consultem o seguinte link: http://scikit-learn.org/stable/modules/preprocessing.html. \n",
    "\n",
    "Q1. Use SVM para classificar os dígitos 5 e 6. Utilize as funções do scikit learn (http://scikit-learn.org/, http://scikit-learn.org/stable/modules/svm.html) para realizar o treinamento.\n",
    "\n",
    "Teste os kernels linear e RBF da seguinte maneira:\n",
    "1. Escolha aleatoriamente 932 amostras para formarem o conjunto de teste.\n",
    "2. Com as 7000 amostras restantes, utilize validação cruzada (com número de folds K = 5) para escolher os parâmetros do seu classificador, isto é: C (peso da *soft margin*) para o kernel linear; C e gamma para o kernel RBF.\n",
    "3. Plote a curva experimental de aprendizado para o melhor SVM com kernel linear e o melhor SVM com kernel RBF escolhidos por validação cruzada. Use as 932 amostras do conjunto de teste para estimar $E_{out}$. Comente sobre o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7932, 257)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('data/train_svm.csv', delimiter=',')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos dados\n",
    "\n",
    "* separação dos dados em conjuntos de imagens e labels de teste (932 amostras selecionadas aleatoriamente) e treino (7000 amostras restantes)\n",
    "* normalização dos valores das imagens usando o preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((7000, 256), (932, 256), (7000,), (932,))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f03eb5e38d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_data(data):\n",
    "    images = np.array([x[1:] for x in data])\n",
    "    labels = np.array([x[0] for x in data])\n",
    "    return [images, labels]\n",
    "\n",
    "images, labels = extract_data(data)\n",
    "images = preprocessing.normalize(images)\n",
    "\n",
    "def shuffle_indices(ndata, ntest):\n",
    "    idtest = np.random.choice(ndata, ntest, replace=False)\n",
    "    idtrain = np.array(filter(lambda x: x not in idtest, range(ndata)))\n",
    "    return [idtrain, idtest]\n",
    "\n",
    "\n",
    "idtrain, idtest = shuffle_indices(7932, 932)\n",
    "\n",
    "img_train = images[idtrain]\n",
    "img_test = images[idtest]\n",
    "lbl_train = labels[idtrain]\n",
    "lbl_test = labels[idtest]\n",
    "\n",
    "print (img_train.shape, img_test.shape, lbl_train.shape, lbl_test.shape)\n",
    "\n",
    "plt.imshow(img_train[0].reshape((16, 16)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ndata = 7000\n",
    "# e_val = []\n",
    "# for C in np.logspace(-3, 8, 12) # testa todos os valores de C = 10^i, com i variando de -3 a 8\n",
    "#     for k in range 5\n",
    "#         lin_clf = svm.SVC(kernel='linear', C=C)\n",
    "#         val_i = range(k*ndata/5, ((k+1)*ndata/5))\n",
    "#         tr_i = filter(lambda x: x not in val_idx, range(ndata))\n",
    "#         lin_clf.fit(img_train[tr_i], lbl_train[tr_i])\n",
    "#         pred = lin_clf.predict(img_train[val_i], lbl_train[val_i])\n",
    "#         e_val.append(sum(abs(pred-lbl_train[val_i]))) \n",
    "\n",
    "\n",
    "# StratifiedShuffleSplit faz o cross-validation. Para esse problema, \n",
    "# estamos separando o dataset de treino (7000 imagens) em 5 grupos. \n",
    "# Em cada rodada, um desses grupos sera removido e usado para \n",
    "# validacao do treino efetuado com os outros 4\n",
    "crossval = StratifiedShuffleSplit(n_splits=5, test_size=0.2)\n",
    "\n",
    "# C vai assumir os valores 10^i, com i variando de -1 a 6\n",
    "c_range = np.logspace(-1, 6, 8) \n",
    "# gamma vai assumir os valores 4^i, com i variando de -4 a 3\n",
    "gamma_range = np.logspace(-4, 3, 8)\n",
    "\n",
    "# GridSearchCV faz uma busca exaustiva no espaco de parametros passado, testando cada um deles\n",
    "grid_lin = GridSearchCV(svm.SVC(kernel='linear', cache_size=1000), \n",
    "                        param_grid=dict(C=c_range), \n",
    "                        cv=crossval, n_jobs=-1)\n",
    "grid_lin.fit(X=img_train, y=lbl_train)\n",
    "\n",
    "print(\"Kernel linear --- \")\n",
    "print(\"Melhor valor para C: %s com e_out de %0.5f\" % (grid_lin.best_params_, grid_lin.best_score_))\n",
    "\n",
    "\n",
    "grid_rbf = GridSearchCV(svm.SVC(kernel='rbf', cache_size=1000), \n",
    "                        param_grid=dict(C=c_range, gamma=gamma_range), \n",
    "                        cv=crossval, n_jobs=-1)\n",
    "grid_rbf.fit(X=img_train, y=lbl_train)\n",
    "\n",
    "print(\"Kernel RBF --- \")\n",
    "print(\"Melhor valor para os parâmetros: %s com e_out de %0.5f\" % (grid_rbf.best_params_, grid_rbf.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
